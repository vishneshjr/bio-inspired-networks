{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\" Loads the MNIST data and returns it as a tuple of the form\n",
    "    (training_data, validation_data, testing_data)\n",
    "    \"\"\"\n",
    "    f = gzip.open('../data/mnist.pkl.gz', 'rb')\n",
    "    train, val, test = pickle.load(f, encoding=\"latin1\")\n",
    "    f.close()\n",
    "    return (train, val, test)\n",
    "\n",
    "\n",
    "def load_data_wrapper():\n",
    "    train, val, test = load_data()\n",
    "    train_input = [np.reshape(x, (len(x), 1)) for x in train[0]] # Reshape input (n, ) to (n, 1)\n",
    "    train_result = [one_hot_encode(y) for y in train[1]]\n",
    "    train_data = list(zip(train_input, train_result))\n",
    "    val_input = [np.reshape(x, (len(x), 1)) for x in val[0]] # Reshape input (n, ) to (n, 1)\n",
    "    val_result = [one_hot_encode(y) for y in val[1]]\n",
    "    val_data = list(zip(val_input, val_result))\n",
    "    test_input = [np.reshape(x, (len(x), 1)) for x in test[0]] # Reshape input (n, ) to (n, 1)\n",
    "    test_result = [one_hot_encode(y) for y in test[1]]\n",
    "    test_data = list(zip(test_input, test_result))\n",
    "\n",
    "    return (train_data, val_data, test_data)\n",
    "\n",
    "\n",
    "def one_hot_encode(n): \n",
    "    \"\"\"Converts a decimal digit into a one-hot encoded vector and returns the vector.\n",
    "    \n",
    "    This is the output that we are trying to match for each digit during prediction.\n",
    "    \"\"\"\n",
    "    v = np.zeros((10, 1))\n",
    "    v[n] = 1.0\n",
    "    return v\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Network Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, sizes, activation = \"Sigmoid\"):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[1:], sizes[:-1])] # Second layer parameter x comes before first layer parameter y to enable matrix multiplication\n",
    "        self.activation_type = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            b = self.biases[i]\n",
    "            w = self.weights[i]\n",
    "            x = self.activation(w @ x + b)\n",
    "        return x\n",
    "    \n",
    "    # Use Leaky RELU by default\n",
    "    def activation(self, x):\n",
    "        if (self.activation_type == \"Leaky RELU\"):\n",
    "            return np.where(x > 0, x, x * 0.03)\n",
    "        elif (self.activation_type == \"Sigmoid\"):\n",
    "            return self.sigmoid(x)\n",
    "        \n",
    "        raise Exception(\"Activation Function Type Does Not Exist\")\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    def activation_derivative(self, x):\n",
    "        if (self.activation_type == \"Sigmoid\"):\n",
    "            return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "\n",
    "\n",
    "        raise Exception(\"Activation Function Type Does Not Exist\")\n",
    "\n",
    "    def SGD(self, train_data, epochs, batch_size, alpha, test_data = None):\n",
    "        n = len(train_data)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(train_data)\n",
    "            batches = [train_data[k: k + batch_size] for k in range(0, n, batch_size)]\n",
    "            \n",
    "            for batch in batches:\n",
    "                self.update(batch, alpha)\n",
    "            \n",
    "            if (test_data):\n",
    "                print(\"Epoch\", i + 1, \"Accuracy: \", self.evaluate(test_data))\n",
    "            else:\n",
    "                print(\"Epoch \", i + 1, \"Complete\")\n",
    "        \n",
    "    def evaluate(self, data):\n",
    "        preds = [1 if (np.argmax(self.forward(x)) == np.argmax(y)) else 0 for x,y in data]\n",
    "        return np.mean(preds)\n",
    "\n",
    "    def update(self, batch, alpha):\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "        for x,y in batch:\n",
    "            del_b, del_w = self.backprop(x, y)\n",
    "            delta_b = [change_b + new_change_b for change_b, new_change_b in zip(delta_b, del_b)]\n",
    "            delta_w = [change_w + new_change_w for change_w, new_change_w in zip(delta_w, del_w)]\n",
    "        \n",
    "        self.weights = [w - alpha*(delw)/len(batch) for w, delw in zip(self.weights, delta_w)]\n",
    "        self.biases = [b - alpha*(delb)/len(batch) for b, delb in zip(self.biases, delta_b)]\n",
    "        \n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = self.sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            self.activation_derivative(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = self.activation_derivative(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "from simple_network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this file\n",
      "/Users/vishnesh/Master/01 - College/06 - Spring '24/PSYC 4803 - Physics of Cognition/Project/bio-inspired-networks/src\n"
     ]
    }
   ],
   "source": [
    "train, val, test = data_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this file\n",
      "/Users/vishnesh/Master/01 - College/06 - Spring '24/PSYC 4803 - Physics of Cognition/Project/bio-inspired-networks/src\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train, val, test \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mload_data_wrapper()\n\u001b[1;32m      6\u001b[0m net \u001b[38;5;241m=\u001b[39m Network([\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/01 - College/06 - Spring '24/PSYC 4803 - Physics of Cognition/Project/bio-inspired-networks/src/simple_network.py:47\u001b[0m, in \u001b[0;36mNetwork.SGD\u001b[0;34m(self, train_data, epochs, batch_size, alpha, test_data)\u001b[0m\n\u001b[1;32m     44\u001b[0m batches \u001b[38;5;241m=\u001b[39m [train_data[k: k \u001b[38;5;241m+\u001b[39m batch_size] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, batch_size)]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (test_data):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(test_data))\n",
      "File \u001b[0;32m~/Master/01 - College/06 - Spring '24/PSYC 4803 - Physics of Cognition/Project/bio-inspired-networks/src/simple_network.py:60\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(self, batch, alpha)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     59\u001b[0m     preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(preds)\n",
      "File \u001b[0;32m~/Master/01 - College/06 - Spring '24/PSYC 4803 - Physics of Cognition/Project/bio-inspired-networks/src/simple_network.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     59\u001b[0m     preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(preds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import data_loader\n",
    "train, val, test = data_loader.load_data_wrapper()\n",
    "\n",
    "net = Network([784, 30, 10])\n",
    "net.SGD(train, 15, 10, 3.0, test_data = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My algorithm thinks the number is  7\n",
      "The number should be 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = test[no][0]\n",
    "ans = np.argmax(test[no][1])\n",
    "print(\"My algorithm thinks the number is \", np.argmax(net.forward(x)))\n",
    "x = np.array(x).reshape(28, 28)\n",
    "\n",
    "plt.imshow(x, cmap='gray')\n",
    "print(\"The number should be\", ans)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
